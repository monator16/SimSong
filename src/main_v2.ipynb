{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user1\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 및 학습 관련 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "    'time' :30, # 각 노래에서 몇 초를 가져올 것인지\n",
    "    'sample_rate' :44100 # [1, sample_rate*time]: time(초)로 구간 설정    \n",
    "}\n",
    "\n",
    "learning_parameters = {\n",
    "    'dataset_dir':'mp3',\n",
    "    'device' : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'epoch': 20,\n",
    "    'batch_size' : 64,\n",
    "    'lr' : 1e-4,\n",
    "    'lr_decay' :0.95,\n",
    "    'ckpt_dir' : None #학습중인 모델의 경로로\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import create_contrastive_datasets, create_datsets, ContrastiveDataset\n",
    "\n",
    "# 오디오 파일 경로 및 데이터셋 준비\n",
    "train_dataset = create_datsets(dataset_dir= learning_parameters['dataset_dir'],\n",
    "                               state = 'train')\n",
    "\n",
    "# ContrastiveDataset으로 변환\n",
    "train_contrastive_dataset = ContrastiveDataset(train_dataset, model_parameters)\n",
    "\n",
    "# DataLoader로 배치 생성\n",
    "train_loader = DataLoader(train_contrastive_dataset, \n",
    "                          batch_size=learning_parameters['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          drop_last =True) \n",
    "#-> 한 배치의 구성 : clip_a, clip_b, file_id\n",
    "\n",
    "# 데이터로더 확인용\n",
    "print('train dataset 크기')\n",
    "print(train_contrastive_dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ContrastiveModel\n",
    "from ast_encoder import ASTEncoder\n",
    "from loss import soft_info_nce_loss, info_nce_loss\n",
    "from loss_weight import generate_lyrics_embeddings, compute_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "# 1. 모델과 옵티마이저 초기화\n",
    "\n",
    "ast_encoder = ASTEncoder()\n",
    "ast_encoder.set_train_mode()\n",
    "ast_encoder.to(learning_parameters['device'])\n",
    "\n",
    "\n",
    "model = ContrastiveModel(ast_encoder)\n",
    "\n",
    "# 체크포인트 불러오기\n",
    "if learning_parameters['ckpt_dir']:\n",
    "    checkpoint = torch.load(learning_parameters['ckpt_dir'], map_location=learning_parameters['device'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Checkpoint loaded from {learning_parameters['ckpt_dir']}\")\n",
    "\n",
    "model.to(learning_parameters['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "#scheduler 추가\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer=optimizer,\n",
    "    lr_lambda=lambda epoch: learning_parameters['lr_decay'] ** epoch,\n",
    "    last_epoch=-1,\n",
    "    verbose=False\n",
    "    )\n",
    "\n",
    "# 2. BERT 모델 로드 (가사 임베딩용)\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.to(learning_parameters['device'])\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from train import AudioLyricsModel\n",
    "\n",
    "# AudioLyricsModel 인스턴스 생성\n",
    "audio_lyrics_model = AudioLyricsModel(\n",
    "    model=model,\n",
    "    lyrics=True,  # 가사 사용 여부 설정 (필요에 따라 True/False 변경)\n",
    "    bert_model=bert_model,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=learning_parameters['batch_size']\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=learning_parameters['epoch'])\n",
    "trainer.fit(audio_lyrics_model, train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
